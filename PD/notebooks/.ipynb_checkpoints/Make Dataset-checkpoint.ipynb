{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Author: Nicolas BultÃ©\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Glossary mapping\n",
    "\"\"\"\n",
    "\n",
    "# LoanID               = Loan Identifier (A,P)\n",
    "# MonthRep             = Monthly Reporting Period (P)\n",
    "# Servicer             = Servicer Name (P)\n",
    "# CurrInterestRate     = CURRENT INTEREST RATE (P)\n",
    "# CAUPB                = CURRENT ACTUAL UNPAID PRINCIPAL BALANCE (P)\n",
    "# LoanAge              = Loan Age (P)\n",
    "# MonthsToMaturity     = Remaining Months to Legal Maturity (P)\n",
    "# AdMonthsToMaturity   = ADJUSTED REMAINING MONTHS TO MATURITY (P)\n",
    "# MaturityDate         = Maturity Date (P)\n",
    "# MSA                  = Metropolitan Statistical Area (P)\n",
    "# CLDS                 = Current Loan Delinquency Status (P)\n",
    "# ModFlag              = Modification Flag (P)\n",
    "# ZeroBalCode          = Zero Balance Code (P)\n",
    "# ZeroBalDate          = Zero Balance Effective Date(P)\n",
    "# LastInstallDate      = LAST PAID INSTALLMENT DATE\n",
    "# ForeclosureDate      = FORECLOSURE DATE\n",
    "# DispositionDate      = DISPOSITION DATE\n",
    "# ForeclosureCosts     = FORECLOSURE COSTS (P)\n",
    "# PPRC                 = Property Preservation and Repair Costs (P)\n",
    "# AssetRecCost         = ASSET RECOVERY COSTS (P)\n",
    "# MHEC                 = Miscellaneous Holding Expenses and Credits (P)\n",
    "# ATFHP                = Associated Taxes for Holding Property (P)\n",
    "# NetSaleProceeds      = Net Sale Proceeds (P)\n",
    "# CreditEnhProceeds    = Credit Enhancement Proceeds (P)\n",
    "# RPMWP                = Repurchase Make Whole Proceeds(P)\n",
    "# OFP                  = Other Foreclosure Proceeds (P)\n",
    "# NIBUPB               = Non-Interest Bearing UPB (P)\n",
    "# PFUPB                = PRINCIPAL FORGIVENESS UPB (P)\n",
    "# RMWPF                = Repurchase Make Whole Proceeds Flag (P)\n",
    "# FPWA                 = Foreclosure Principal Write-off Amount (P)\n",
    "# ServicingIndicator   = SERVICING ACTIVITY INDICATOR (P)\n",
    "\n",
    "\"\"\"\n",
    "    Import statements \n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import datasets, select features and define the default-flag collumn.\n",
    "col_per = ['LoanID', 'MonthRep', 'Servicer', 'CurrInterestRate', 'CAUPB', 'LoanAge', 'MonthsToMaturity',\n",
    "           'AdMonthsToMaturity', 'MaturityDate', 'MSA', 'CLDS', 'ModFlag', 'ZeroBalCode', 'ZeroBalDate',\n",
    "           'LastInstallDate', 'ForeclosureDate', 'DispositionDate', 'ForeclosureCosts', 'PPRC', 'AssetRecCost', 'MHEC',\n",
    "           'ATFHP', 'NetSaleProceeds', 'CreditEnhProceeds', 'RPMWP', 'OFP', 'NIBUPB', 'PFUPB', 'RMWPF',\n",
    "           'FPWA', 'ServicingIndicator']\n",
    "\n",
    "# Python will guess the datatypes not specified in the map function, for dates the dtype will be 'object'. (hence: here all dates)\n",
    "# If an expected integer variables contains NaN values it will be set to 'float32'\n",
    "perf_type_map = {'LoanID': 'int64', 'Servicer': 'category', 'CurrInterestRate': 'float32', 'CAUPB': 'float32',\n",
    "                 'LoanAge': 'int64', 'MonthsToMaturity': 'int64', 'AdMonthsToMaturity': 'float32', 'MSA': 'category',\n",
    "                 'CLDS': 'category', 'ModFlag': 'category', 'ZeroBalCode': 'float32', 'ForeclosureCosts': 'float32',\n",
    "                 'PPRC': 'float32', 'AssetRecCost': 'float32', 'MHEC': 'float32', 'ATFHP': 'float32',\n",
    "                 'NetSaleProceeds': 'float32', 'CreditEnhProceeds': 'float32', 'RPMWP': 'float32', 'OFP': 'float32',\n",
    "                 'NIBUPB': 'float32', 'PFUPB': 'float32', 'RMWPF': 'category', 'FPWA': 'float32',\n",
    "                 'ServicingIndicator': 'category'}\n",
    "\n",
    "extended_selec_per = col_per\n",
    "\n",
    "col_per_subset = extended_selec_per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_name, ref_year, lines_to_read=None):\n",
    "    \"\"\"\n",
    "    Read file in function to avoid memory issues\n",
    "    + Add lagged payment variables\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_name: Path name of the file;\n",
    "    ref_year: Specify the list of years to be read, if None-> whole dataset is used;\n",
    "    lines_to_read: Specify the number of rows of the dataset to be read.\n",
    "    Returns\n",
    "    -------\n",
    "    Raw performance dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(file_name, sep='|', names=col_per, dtype=perf_type_map, usecols=col_per_subset, index_col=False,\n",
    "                     nrows=lines_to_read)\n",
    "    if ref_year != None:\n",
    "        df = df[df.MonthRep.str.contains('|'.join(ref_year))]\n",
    "    # Add lagged deliquincy payment value based on CLDS\n",
    "    df['CLDS'] = df.CLDS.replace('X', '1').astype('float')\n",
    "    df.loc[df.CLDS == 0.0, 'Arrears'] = 0\n",
    "    df.loc[df.CLDS != 0.0, 'Arrears'] = 1\n",
    "    df['Arrears_3m'] = df['Arrears'].rolling(min_periods=3, window=3).apply(\n",
    "        lambda x: x.sum() if x.sum() < 3 else 0, raw=True).astype('category')\n",
    "    df['Arrears_6m'] = df['Arrears'].rolling(min_periods=6, window=6).apply(\n",
    "        lambda x: x.sum() if x.sum() < 6 else 0, raw=True).astype('category')\n",
    "    df['Arrears_9m'] = df['Arrears'].rolling(min_periods=9, window=9).apply(\n",
    "        lambda x: x.sum() if x.sum() < 9 else 0, raw=True).astype('category')\n",
    "    df['Arrears_12m'] = df['Arrears'].rolling(min_periods=12, window=12).apply(\n",
    "        lambda x: x.sum() if x.sum() < 12 else 0, raw=True).astype('category')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_12mDefault(date, perf_df):\n",
    "    \"\"\"\n",
    "    Create the 12 month forward looking default flag.\n",
    "    Parameters\n",
    "    ----------\n",
    "    date: Snapshot date\n",
    "    perf_df: Performance dataframe\n",
    "    Returns\n",
    "    -------\n",
    "    Raw observation dataframe\n",
    "    \"\"\"\n",
    "    cur_date = dt.datetime.strptime(date, '%m/%d/%Y').date()\n",
    "    # Fix the IDs in the observation set by fixing their reporting date AND requiring that the files are healthy.\n",
    "    obs_df = perf_df[(perf_df.MonthRep == date)\n",
    "                     &\n",
    "                     ((perf_df.CLDS == 0.0) |\n",
    "                      (perf_df.CLDS == 1.0) |\n",
    "                      (perf_df.CLDS == 2.0)\n",
    "                      )\n",
    "                     ]\n",
    "    obs_ids = obs_df.LoanID\n",
    "    # Load only the observation IDs in the performance frame initially.\n",
    "    pf = perf_df[perf_df.LoanID.isin(obs_ids)]\n",
    "\n",
    "    # Create the 12 month forward looking list of dates\n",
    "    date_list = []\n",
    "    for i in np.arange(0, 12):\n",
    "        if cur_date.month == 12:\n",
    "            month = 1\n",
    "            year = cur_date.year + 1\n",
    "        else:\n",
    "            month = cur_date.month + 1\n",
    "            year = cur_date.year\n",
    "        next_date = dt.datetime(year, month, cur_date.day)\n",
    "        date_list.append(next_date.strftime('%m/%d/%Y'))\n",
    "        cur_date = next_date\n",
    "\n",
    "    # Find the LoanIDs of those loans where a default appears in our 12 month forward looking period.\n",
    "    pf_obs = perf_df[perf_df.MonthRep.isin(date_list)]\n",
    "    pf_obs_defaults = pf_obs[\n",
    "        (pf_obs.CLDS != 0.0) &\n",
    "        (pf_obs.CLDS != 1.0) &\n",
    "        (pf_obs.CLDS != 2.0)\n",
    "        ].LoanID\n",
    "\n",
    "    pf_obs_defaults = pf_obs_defaults.drop_duplicates(keep='last').values\n",
    "    df = obs_df\n",
    "    df['Default'] = 0\n",
    "    df.loc[df['LoanID'].isin(pf_obs_defaults), 'Default'] = 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_default_dupl(observ_df):\n",
    "    \"\"\"\n",
    "    Remove observations with more than one default in observation dataframe\n",
    "    Parameters\n",
    "    ----------\n",
    "    observ_df: observation dataframe\n",
    "    Returns\n",
    "    -------\n",
    "    final observation dataframe\n",
    "    \"\"\"\n",
    "    # Check in observation frame for Loans with more than one defaults per loan ID:\n",
    "    dft_per_loan = observ_df.groupby('LoanID').Default.sum()\n",
    "    # List of Loan IDs with more than 1 default:\n",
    "    dft_per_loan_ids = dft_per_loan[dft_per_loan > 1].index.tolist()\n",
    "    # Dataframe of loans with more than 1 default:\n",
    "    dft_per_loan_df = observ_df[observ_df.LoanID.isin(dft_per_loan_ids)]\n",
    "    # Remove Loans with default flag=0 (cured or not yet in default) and keep 'first' appearing default:\n",
    "    dft_per_loan_df = dft_per_loan_df[dft_per_loan_df.Default > 0].drop_duplicates(subset='LoanID', keep='first')\n",
    "    # Healthy dataframe without any loans with more than 1 default\n",
    "    healthy_frame = observ_df.drop(observ_df[observ_df.LoanID.isin(dft_per_loan_ids)].index)\n",
    "    # Concat healthy frame and frame containing the filtered loans with\n",
    "    observs_df_new = pd.concat([healthy_frame, dft_per_loan_df])\n",
    "\n",
    "    return observs_df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_sample(observ_df):\n",
    "    '''\n",
    "    Select randomly 1/8 of the accounts from each of the 8 quarterly snapshot; an account should appear only once. \n",
    "    This way, the final sample will have an even mix of each quarter and will be equivalent size of the portfolio \n",
    "    on average over the 2 years.\n",
    "    Parameters\n",
    "    ----------\n",
    "    observ_df: observation dataframe\n",
    "    Returns\n",
    "    -------\n",
    "    '''\n",
    "    snapshots = observ_df.MonthRep.unique()\n",
    "    # Store the size of (in case of 8 snapshot dates) 1/8 of the dataset, divided by 8 again to get the size of 1/8 of a snapshot set. \n",
    "    # Use this to sample from every snapshot set to come to a final df that contains the 1/8 of the original size and has equal\n",
    "    # contribution of every quarter/snapshot moment. \n",
    "    i = int(observ_df.shape[0] / len(snapshots) / len(snapshots))\n",
    "    l = []\n",
    "    for d in snapshots:\n",
    "        l.append(observ_df[observ_df.MonthRep == d].sample(n=i, replace=False, random_state=1))\n",
    "    df = pd.concat(l)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_wo_duplicates(observ_df):\n",
    "    \"\"\"\n",
    "    Sampling without duplicates.\n",
    "    Parameters\n",
    "    ----------\n",
    "    observ_df: the complete observation frame\n",
    "    Returns\n",
    "    -------\n",
    "    Sampled frame\n",
    "    \"\"\"\n",
    "    snapshots = pre_frame.MonthRep.unique()\n",
    "    snapshots_dates = [dt.datetime.strptime(d, '%m/%d/%Y').date() for d in snapshots]\n",
    "    sample_list = []\n",
    "    loanids_list = []\n",
    "    for d in sorted(snapshots_dates)[::-1]:  # Backward looking\n",
    "        snap_df = pre_frame[pre_frame.MonthRep == d.strftime(\"%m/%d/%Y\")]\n",
    "        i = int(snap_df.shape[0] / len(snapshots))\n",
    "        #print('value of 1/8 of the snapshote dataframe= ', i)\n",
    "        j = len(snap_df)\n",
    "        # Drop duplicates:\n",
    "        if loanids_list != None:\n",
    "            #print('Number of duplicates to kick out= ', snap_df.LoanID.isin(loanids_list).sum())\n",
    "            snap_df = snap_df[~snap_df.LoanID.isin(loanids_list)]\n",
    "            #print('Check', j - len(snap_df))\n",
    "        # Sample\n",
    "        sampled_df = snap_df.sample(n=i, replace=False, random_state=1)\n",
    "        # print('Length of sampled df=', len(sampled_df))\n",
    "        sample_list.append(sampled_df)\n",
    "        loanids_list.extend(sampled_df.LoanID.unique().tolist())\n",
    "    agg_sample_df = pd.concat(sample_list)\n",
    "    return agg_sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traintest_split(observation_frame, testsize=0.2):\n",
    "    X = observation_frame.drop('Default', axis=1)\n",
    "    Y = observation_frame.Default\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=testsize, random_state=1)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bebxadvberb\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2903: DtypeWarning: Columns (14,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "C:\\Users\\bebxadvberb\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\bebxadvberb\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Read the file Performance_HARP.txt: http://www.fanniemae.com/portal/funding-the-market/data/loan-performance-data.html\n",
    "    performance_frame = read_file(file_name='C:/Users/bebxadvberb/Documents/AI/Trusted AI/Performance_HARP.txt', ref_year=['2016', '2017', '2018'],\n",
    "                                  lines_to_read=1e5)\n",
    "    # Define your snapshot dates for your observation frame:\n",
    "    date_list = ['03/01/2016', '06/01/2016', '09/01/2016', '12/01/2016', '03/01/2017', '06/01/2017', '09/01/2017',\n",
    "                 '12/01/2017']\n",
    "    pre_frame = pd.concat([create_12mDefault(d, performance_frame) for d in date_list])\n",
    "    # Remove observations with several defaults:\n",
    "    pre_frame = remove_default_dupl(pre_frame)\n",
    "    # Sampling\n",
    "    observation_frame = sample_wo_duplicates(pre_frame)\n",
    "    # observation_frame = select_sample(pre_frame)\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = traintest_split(observation_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bebxadvberb\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\api.py:107: RuntimeWarning: '<' not supported between instances of 'str' and 'int', sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LoanID                0\n",
       "MonthRep              0\n",
       "Servicer              0\n",
       "CurrInterestRate      0\n",
       "CAUPB                 0\n",
       "LoanAge               0\n",
       "MonthsToMaturity      0\n",
       "AdMonthsToMaturity    0\n",
       "MaturityDate          0\n",
       "MSA                   0\n",
       "CLDS                  0\n",
       "ModFlag               0\n",
       "ZeroBalCode           0\n",
       "ZeroBalDate           0\n",
       "LastInstallDate       0\n",
       "ForeclosureDate       0\n",
       "DispositionDate       0\n",
       "ForeclosureCosts      0\n",
       "PPRC                  0\n",
       "AssetRecCost          0\n",
       "MHEC                  0\n",
       "ATFHP                 0\n",
       "NetSaleProceeds       0\n",
       "CreditEnhProceeds     0\n",
       "RPMWP                 0\n",
       "OFP                   0\n",
       "NIBUPB                0\n",
       "PFUPB                 0\n",
       "RMWPF                 0\n",
       "FPWA                  0\n",
       "ServicingIndicator    0\n",
       "Arrears               0\n",
       "Arrears_3m            0\n",
       "Arrears_6m            0\n",
       "Arrears_9m            0\n",
       "Arrears_12m           0\n",
       "Default               8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([X_train,y_train])\n",
    "df.rename(columns={0:'Default'}, inplace=True)\n",
    "df[df['Default']==1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
